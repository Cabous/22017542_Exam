---
output:
  md_document:
    variant: markdown_github
---
# Financial Econometrics Practical

This is my README for the Financial Econometrics Practical Exam 2022


```{r}

#rm(list = ls()) 
#gc() 

library(tidyverse)
library(zoo)
library(factoextra)
pacman::p_load(cowplot, glue, tbl2xts)
pacman::p_load("MTS", "robustbase")

pacman::p_load("tidyverse", "devtools", "rugarch", "rmgarch", 
     "forecast", "tbl2xts", "lubridate", "PerformanceAnalytics", 
     "ggthemes", "dplyr", "cowplot", "fmxdat") 

list.files('C:/Users/Cabous/OneDrive/Desktop/22017542_Exam/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

```

# Question 1: Yield Spreads

## Import Data

```{r}

SA_bonds <- read_rds("data/SA_Bonds.rds")

BE_Inflation <- read_rds("data/BE_Infl.rds")

bonds_2y <- read_rds("data/bonds_2y.rds")

bonds_10y <- read_rds("data/bonds_10y.rds")

usdzar <- read_rds("data/usdzar.rds")

ZA_Inflation <- read_rds("data/ZA_Infl.rds")

IV <- read_rds("data/IV.rds")

```

## Compare spreads

```{r}

pacman::p_load(fmxdat)

# Sort data and calculate spreads.

SA_Spreads <- SA_bonds %>% 
    
    arrange(date) %>% 
    
    group_by(date) %>% 
    
    mutate("10Yr2Yr" = ZA_10Yr - ZA_2Yr) %>% 
    
    mutate("10Yr3M" = ZA_10Yr - SA_3M) %>% 
    
    mutate("2Yr3M" = ZA_2Yr - SA_3M) %>% 

    ungroup() %>% 
    
    pivot_longer(c("10Yr2Yr", "10Yr3M", "2Yr3M"), names_to = "Spreads", values_to = "Rates") %>% 
    
    filter(date >= as.Date("2000/01/01"))

```

# Plot the spreads

```{r}

SA_Spread_plot <- SA_Spreads %>% 
    
    ggplot() +
    
    geom_line(aes(date, Rates, colour = Spreads), alpha = 0.8) +
    
    labs(title = "Yeild Spread in Local Bond Market", 
         
         subtitle = "3 Month, 2 Year and 10 year bond yields",
         
         y = "Yield Spread", x ="") +
    
    fmxdat::theme_fmx() + 
    
    fmxdat::fmx_cols()


fmxdat::finplot(SA_Spread_plot, x.date.type = "%Y%m", x.vert = TRUE)

```

I can confirm that bond yields have since 2020 been the highest in two decades.

```{r}

library(dplyr)
library(tidyr)
pacman::p_load(lubridate)

# Lets combine ZA and BE inflation (Monthly)
# Note: BE starting date (2012-05-07)

BE_Inflation_clean <- BE_Inflation %>% 
    
    arrange(date) %>% 
    
    rename(BE_Inflation = Price) %>% 
    
    select(-Name) %>%  
                  
    filter(date >= as.Date("2012/05/07")) %>% 
    
    mutate(YM = format(date, "%Y%m")) %>%
    
    group_by(YM) %>% 
    
    filter(date == last(date)) %>% 
    
    select(-date) %>% 
    
    ungroup()


ZA_Inflation_clean <- ZA_Inflation %>% 
                  
        arrange(date) %>%
            
        rename(ZAR_Infl = Price) %>% 
            
        select(-Name) %>% 
            
        filter(date >= as.Date("2012/05/07")) %>% 
    
        mutate(YM = format(date, "%Y%m")) %>%
    
        group_by(YM) %>% 
    
        filter(date == last(date)) %>% 
    
        select(-date) %>% 
            
        ungroup() 
        
ZA_BE_Inflation <- BE_Inflation_clean %>% 
    
    inner_join(ZA_Inflation_clean) %>% 
    
    inner_join(.,SA_bonds %>% 
    
    arrange(date) %>% 
    
    group_by(date) %>% 
    
    mutate("10Yr2Yr" = ZA_10Yr - ZA_2Yr) %>% 
        
        filter(date >= as.Date("2012/05/07")) %>% 
    
        mutate(YM = format(date, "%Y%m")) %>%
    
        group_by(YM) %>% 
    
        filter(date == last(date)) %>% 
    
        select(-date, -SA_3M, -ZA_10Yr, -ZA_2Yr) %>% 
            
    ungroup()) 

    
ZA_BE_Inflation <- ZA_BE_Inflation %>% 
    
    pivot_longer(c("10Yr2Yr", "BE_Inflation", "ZAR_Infl"),
                 
                 names_to = "Spreads", values_to = "Rates") %>%
    
    mutate(date = ym(YM))

# Plot 

Spread_Infl_plot <- ZA_BE_Inflation %>%
    
    ggplot() +
    
    geom_line(aes(date, Rates, colour = Spreads), alpha = 0.8) +
    
    labs(title = "SA 10 year Spread and Inflation",
         
         y = "Yield Spreads", x ="", 
         
         subtitle = "Includes Inflation, Break-Even 10 Year Inflation and 10/2 year yield spread") +
    
    fmxdat::theme_fmx(title.size = ggpts(25), subtitle.size = ggpts(20)) + 
    
    fmxdat::fmx_cols()

fmxdat::finplot(Spread_Infl_plot, x.date.type = "%Y%m", x.vert = TRUE)

```


# Compare to International Spreads

```{r}

#bonds_10y %>% pull(Name) %>% unique()

Names_2yr <- c("Philippines_2yr", "Germany_2yr", "US_2yr")

Names_10yr <- c("Philippines_10Yr", "Germany_10Yr", "US_10Yr")


bonds_2y10y_combine <-  bonds_2y %>% 
    
    arrange(date) %>% 
    
    group_by(date) %>% 
    
    filter(date >= as.Date("2000/01/01")) %>%
    
    filter(Name %in% Names_2yr) %>% 
    
    spread(Name, Bond_2Yr) %>% 
    
    ungroup() %>% 
    
    left_join(., bonds_10y %>% 
                  
    arrange(date) %>% 
    
    group_by(date) %>% 
    
    filter(date >= as.Date("2000/01/01")) %>%
    
    filter(Name %in% Names_10yr) %>% 
    
    spread(Name, Bond_10Yr) %>% 
    
    ungroup())

bonds_2y10y_spread <- bonds_2y10y_combine %>% 
    
    group_by(date) %>% 
    
    mutate(US_10Yr2Yr = US_10Yr - US_2yr, 
           PHILL_10Yr2Yr = Philippines_10Yr - Philippines_2yr,
           Germany_10Yr2Yr = Germany_10Yr - Germany_2yr) %>% 
    
    ungroup() %>% 
    
    inner_join(.,SA_bonds %>% 
    
    arrange(date) %>% 
    
    group_by(date) %>% 
    
    mutate("SA_10Yr2Yr" = ZA_10Yr - ZA_2Yr) %>% 
    
    filter(date >= as.Date("2000/01/01"))) %>% 
    
    select(date, SA_10Yr2Yr, US_10Yr2Yr,PHILL_10Yr2Yr, Germany_10Yr2Yr) %>% 
    
    pivot_longer(c("US_10Yr2Yr", 
                   #"PHILL_10Yr2Yr", 
                   "Germany_10Yr2Yr",
                   "SA_10Yr2Yr"), 
                 names_to = "Spreads", values_to = "Rates") 

# Plot the spreads

compare_spread_plot <- bonds_2y10y_spread %>% 
    
    arrange(date) %>% 
    
    ggplot() +
    
    geom_line(aes(date, Rates, colour = Spreads), alpha = 0.8) +
    
    labs(title = "Relative Long Term Spreads", 
         y = "Spreads (Yields)", x ="", 
         subtitle = "Includes US, Philippines, Germany and SA") +
    
    fmxdat::theme_fmx(title.size = ggpts(30), subtitle.size = ggpts(22), legend.size = ggpts(20)) + 
    
    fmxdat::fmx_cols()

fmxdat::finplot(compare_spread_plot, x.date.type = "%Y%m", x.vert = TRUE)
```

# Question 2: Portfolio Construction

## Import Data

```{r}

T40 <- read_rds("data/T40.rds")

RebDays <- read_rds("data/Rebalance_days.rds")

```

```{r}
# First: calculate ordinary returns
library(lubridate)

#------------------ 
# Step one: gather to make tidy:
 
# lets try: large caps J200

# First the weights:

W_xts_L200 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J200) %>% 
    
    #mutate(J200 = J200*Return) %>% 
    
    filter(date >= as.Date("2010/01/01")) %>% 
    
    filter(Index_Name == "Large_Caps") %>% 
    
    filter(date == first(date)) %>%
    
    mutate(weight = 1/n()) %>% 
    
    tbl_xts(., cols_to_xts = weight, spread_by = Tickers)

# Now Returns:
R_xts_L200 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J200) %>%
    
    #mutate(J200 = J200*Return) %>% 
    
    filter(date >= as.Date("2010/01/01")) %>% 
    
    filter(Index_Name == "Large_Caps") %>% 
    
    tbl_xts(., cols_to_xts = Return, spread_by = Tickers)

# Now... first ensure that column names between R_xts and
# W_xts match:

R_xts_L200 <- R_xts_L200[, names(W_xts_L200)]

# Set all NA returns to zero:

R_xts_L200[is.na(R_xts_L200)] <- 0

# Set all NA weights to zero:

W_xts_L200[is.na(W_xts_L200)] <- 0

# Also set NA's to zero:

Portfolio_L200 <- rmsfuns::Safe_Return.portfolio(R = R_xts_L200, weights = W_xts_L200, 
                                            geometric = TRUE)

Portf_Rets_L200 <- Portfolio_L200$portfolio.returns %>% xts_tbl() 

# Now large caps J400

# First the weights:

W_xts_L400 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J400) %>% 
    
    filter(date >= as.Date("2010/01/01")) %>% 
    
    #mutate(Return = coalesce(Return, 0)) %>% 
    
   # mutate(J400 = J400*Return) %>%
    
    filter(Index_Name == "Large_Caps") %>% 
    
    filter(date == first(date)) %>%
    
    mutate(weight = 1/n()) %>% 
    
    tbl_xts(., cols_to_xts = weight, spread_by = Tickers)

# Now Returns:
R_xts_L400 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J400) %>% 
    
    filter(date >= as.Date("2010/01/01")) %>% 
    
    filter(Index_Name == "Large_Caps") %>% 
    
    tbl_xts(., cols_to_xts = Return, spread_by = Tickers)

# Now... first ensure that column names between R_xts and
# W_xts match:

R_xts_L400 <- R_xts_L400[, names(W_xts_L400)]

# Set all NA returns to zero:

R_xts_L400[is.na(R_xts_L400)] <- 0

# Set all NA weights to zero:

W_xts_L400[is.na(W_xts_L400)] <- 0

# Also set NA's to zero:

Portfolio_L400 <- rmsfuns::Safe_Return.portfolio(R = R_xts_L400, weights = W_xts_L400, 
                                            geometric = TRUE)

Portf_Rets_L400 <- Portfolio_L400$portfolio.returns %>% xts_tbl()

# Join L200 and L400 to plot

Portf_Rets_L200 <- Portf_Rets_L200 %>% mutate(Index = "J200") 
    
Portf_Rets_L400 <- Portf_Rets_L400 %>% mutate(Index = "J400") 

# combine

Portf_Rets_L <- rbind.data.frame(Portf_Rets_L200, Portf_Rets_L400)
```

```{r}
# Plot
Portf_Rets_L %>% 
    
    arrange(date) %>% 
    
    #group_by(Index) %>% 
    
# Set NA Rets to zero to make cumprod work:
#mutate(Rets = coalesce(ret, 0)) %>% 
    
    mutate(CP = cumprod(1 + portfolio.returns)) %>% 
    
    mutate(CP = CP / first(CP)) %>% 
    
    #ungroup() %>% 
    
   # arrange(date) %>% 
    
    ggplot() +
    
    geom_line(aes(date, CP, color = Index), alpha = 0.8) +
    
    labs(title = "Cumulative Returns per Index for ALSI and SWIX",
         subtitle = "Large Caps",
         y = "Cumulative Returns", x ="") +
    
    fmxdat::theme_fmx(title.size = ggpts(30), subtitle.size = ggpts(25), legend.size = ggpts(20))
```



# Mid-Caps
```{r}
W_xts_M200 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J200) %>% 
    
    #mutate(J200 = J200*Return) %>% 
    
    filter(date >= as.Date("2008/01/01")) %>% 
    
    filter(Index_Name == "Small_Caps") %>% 
    
    filter(date == first(date)) %>%
    
    mutate(weight = 1/n()) %>% 
    
    tbl_xts(., cols_to_xts = weight, spread_by = Tickers)

# Now Returns:
R_xts_M200 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J200) %>%
    
    filter(date >= as.Date("2008/01/01")) %>% 
    
    filter(Index_Name == "Small_Caps") %>%
    
    na.locf(.,na.rm=T, 10) %>%
    
    tbl_xts(., cols_to_xts = Return, spread_by = Tickers)

# Now... first ensure that column names between R_xts and
# W_xts match:

R_xts_M200 <- R_xts_M200[, names(W_xts_M200)]

# Set all NA returns to zero:

R_xts_M200[is.na(R_xts_M200)] <- 0

# Set all NA weights to zero:

W_xts_M200[is.na(W_xts_M200)] <- 0

# Also set NA's to zero:

Portfolio_M200 <- rmsfuns::Safe_Return.portfolio(R = R_xts_M200, weights = W_xts_M200, 
                                            geometric = TRUE)

Portf_Rets_M200 <- Portfolio_M200$portfolio.returns %>% xts_tbl() 

# Now large caps J400

# First the weights:

W_xts_M400 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J400) %>% 
    
    filter(date >= as.Date("2008/01/01")) %>% 
    
    #mutate(Return = coalesce(Return, 0)) %>% 
    
   # mutate(J400 = J400*Return) %>%
    
    filter(Index_Name == "Small_Caps") %>% 
    
    filter(date == first(date)) %>%
    
    mutate(weight = 1/n()) %>% 
    
    tbl_xts(., cols_to_xts = weight, spread_by = Tickers)

# Now Returns:
R_xts_M400 <- T40 %>% 
    
    arrange(date) %>% 
    
    select(date, Tickers, Return, Index_Name, J400) %>% 
    
    filter(date >= as.Date("2008/01/01")) %>% 
    
    filter(Index_Name == "Small_Caps") %>%
    
    na.locf(.,na.rm=T, 10) %>% 
    
    tbl_xts(., cols_to_xts = Return, spread_by = Tickers)

# Now... first ensure that column names between R_xts and
# W_xts match:

R_xts_M400 <- R_xts_M400[, names(W_xts_M400)]

# Set all NA returns to zero:

R_xts_M400[is.na(R_xts_M400)] <- 0

# Set all NA weights to zero:

W_xts_M400[is.na(W_xts_M400)] <- 0

# Also set NA's to zero:

Portfolio_M400 <- rmsfuns::Safe_Return.portfolio(R = R_xts_M400, weights = W_xts_M400, 
                                            geometric = TRUE)

Portf_Rets_M400 <- Portfolio_M400$portfolio.returns %>% xts_tbl()

# Join L200 and L400 to plot

Portf_Rets_M200 <- Portf_Rets_M200 %>% mutate(Index = "J200") 
    
Portf_Rets_M400 <- Portf_Rets_M400 %>% mutate(Index = "J400") 

# combine

Portf_Rets_M <- rbind.data.frame(Portf_Rets_M200, Portf_Rets_M400)

# Plot
Portf_Rets_M %>% 
    
    arrange(date) %>% 
    
# Set NA Rets to zero to make cumprod work:
#mutate(Rets = coalesce(ret, 0)) %>% 
    
    mutate(CP = cumprod(1 + portfolio.returns)) %>% 
    
    ungroup() %>% 
    
   # arrange(date) %>% 
    
    ggplot() +
    
    geom_line(aes(date, CP, color = Index), alpha = 0.8)+
    labs(title = "Cumulative Returns per Index for ALSI and SWIX",
         subtitle = "Small Caps",
         y = "Cumulative Returns", x ="") +
    
    fmxdat::theme_fmx(title.size = ggpts(30), subtitle.size = ggpts(25), legend.size = ggpts(20))


```



```{r}
# Construct Capped Portfolio and Determine Performance for ALSI

reb_ALSI <- T40 %>% 
    
    filter(date %in% RebDays$date) %>% 
    
# Now we have to distinguish rebalances - to create something
# to group by:
    
    mutate(RebalanceTime = format(date, "%Y%B")) %>% 
    
    select(date, Tickers, Return, J200, RebalanceTime) %>% 
    
    rename(weight = J200) %>% 
    
    mutate(weight = coalesce(weight , 0))
  
# Apply Proportional_Cap_Foo to ALSI to get capped return for cap of 10%

Capped_df <- reb_ALSI %>% 
    
    group_split(RebalanceTime) %>% 
    
    map_df(~Proportional_Cap_Foo(., W_Cap = 0.1) ) %>% 
    
    select(-RebalanceTime)
 

ALSI_wts <- Capped_df %>% 
    
    tbl_xts(cols_to_xts = weight, spread_by = Tickers)


ALSI_rts <- T40 %>% 
    
    filter(Tickers %in% unique(Capped_df$Tickers)) %>% 
    
    tbl_xts(cols_to_xts = Return, spread_by = Tickers)


ALSI_wts[is.na(ALSI_wts)] <- 0

ALSI_rts[is.na(ALSI_rts)] <- 0


ALSI_capped <- rmsfuns::Safe_Return.portfolio(R = ALSI_rts, weights = ALSI_wts, 
    lag_weights = T) %>% 
    
    xts_tbl() %>% 
    
    rename(ALSI = portfolio.returns)

# Construct Capped Portfolio and Determine Performance for SWIX

reb_SWIX <- T40 %>% 
    
    filter(date %in% RebDays$date) %>%
    
    mutate(RebalanceTime = format(date, "%Y%B")) %>%
    
    select(date, Tickers, Return, J400, RebalanceTime) %>% 
    
    rename(weight = J400) %>% 
    
    mutate(weight = coalesce(weight , 0))
  
# Apply Proportional_Cap_Foo to ALSI to get capped return for cap of 6%

Capped_df <- reb_SWIX %>% 
    
    group_split(RebalanceTime) %>% 
    
    map_df(~Proportional_Cap_Foo(., W_Cap = 0.06) ) %>% 
    
    select(-RebalanceTime)
 

SWIX_wts <- Capped_df %>% 
    
    tbl_xts(cols_to_xts = weight, spread_by = Tickers)


SWIX_rts <- T40 %>% 
    
    filter(Tickers %in% unique(Capped_df$Tickers)) %>%
    
    tbl_xts(cols_to_xts = Return, spread_by = Tickers)


SWIX_wts[is.na(SWIX_wts)] <- 0

SWIX_rts[is.na(SWIX_rts)] <- 0


SWIX_capped <- rmsfuns::Safe_Return.portfolio(R = SWIX_rts, weights = SWIX_wts, 
    lag_weights = T) %>% 
    
    xts_tbl() %>% 
    
rename(SWIX = portfolio.returns)


# Combine and Plot Performance

capped_indices <- left_join(ALSI_capped, SWIX_capped, by = "date") %>% 
    
    pivot_longer(c("ALSI", "SWIX"), names_to = "Meth", values_to = "returns")

# Calculate Uncapped Return for ALSI
ALSI_wts <- T40 %>% 
    
    filter(date %in% RebDays$date) %>%
    
    mutate(RebalanceTime = format(date, "%Y%B")) %>% 
    
    rename(weight = J200) %>% 
    
    mutate(weight = coalesce(weight , 0)) %>%
    
    select(date, Tickers, Return, weight, RebalanceTime) %>% 
    
    tbl_xts(cols_to_xts = weight, spread_by = Tickers)


ALSI_wts[is.na(ALSI_wts)] <- 0

ALSI_rts[is.na(ALSI_rts)] <- 0

ALSI_capped <- rmsfuns::Safe_Return.portfolio(R = ALSI_rts, weights = ALSI_wts, 
    lag_weights = T) %>% 
    
    xts_tbl() %>% 
    
rename(ALSI = portfolio.returns)

# Calculate Uncapped Return for SWIX
 
SWIX_wts <- T40 %>% 
    
    filter(date %in% RebDays$date) %>% 
    
    mutate(RebalanceTime = format(date, "%Y%B")) %>% 
    
    rename(weight = J400) %>% 
    
    mutate(weight = coalesce(weight , 0)) %>% 
    
    select(date, Tickers, Return, weight, RebalanceTime) %>% 
    
    tbl_xts(cols_to_xts = weight, spread_by = Tickers)


SWIX_wts[is.na(SWIX_wts)] <- 0

SWIX_rts[is.na(SWIX_rts)] <- 0

SWIX_capped <- rmsfuns::Safe_Return.portfolio(R = SWIX_rts, weights = SWIX_wts, 
    lag_weights = T) %>% 
    
    xts_tbl() %>% 
    
rename(SWIX = portfolio.returns)

# Combine and Plot

ALSI_SWIX <- left_join(ALSI_capped, SWIX_capped, by = "date") %>% 
    
    pivot_longer(c("ALSI", "SWIX"), names_to = "Meth", values_to = "Returns")

q2_p3 <- capped_indices %>% 
    
    group_by(Meth) %>%
    
    mutate(Idx = cumprod(1 + returns)) %>% 
    
ggplot() + 
    
geom_line(aes(date, Idx, colour = Meth), alpha = 0.8) + 
    
labs(subtitle = "ALSI capped at 10% and SWIX at 6%", 
    x = "", y = "Cumulative Return") +
    
    fmx_cols() + 
    
fmxdat::theme_fmx(subtitle.size = ggpts(20))


q2_p4 <- ALSI_SWIX %>% 
    
    group_by(Meth) %>%
    
    mutate(Idx = cumprod(1 + Returns)) %>% 
    
ggplot() + 
    
geom_line(aes(date, Idx, colour = Meth), alpha = 0.8) + 
    
labs(subtitle = "Uncapped Index Calculation for ALSI and SWIX", 
    x = "", y = "Cumulative Return") + 
    
    fmx_cols() +
    
fmxdat::theme_fmx(subtitle.size = ggpts(20))

plot_grid(finplot(q2_p3), finplot(q2_p4), labels = list(title = "Comparing Capped and Uncapped returns of ALSI and SWIX"), label_size = ggpts(30), align = "h")





```

# Question 4

# Import Data

```{r}

T40 <- read_rds("data/T40.rds")

```

# Calculate Returns

```{r}

T40_Q4 <- T40 %>% 
    
    na.locf(.,na.rm=T, 5) %>%
    
    select(date, Tickers, Return, J200) %>%
    
    mutate(Return = Return*J200) %>%
    
    select(date, Tickers, Return) %>% 
    
    group_by(Tickers) %>%
    
    mutate(Tickers = gsub(" SJ Equity", "", Tickers))

# PCA using princomp

# prcomp requires wide, numeric data:

return_mat <- T40_Q4 %>% spread(Tickers,Return)

colSums(is.na(T40_Q4))

```

```{r}

options(scipen = 999) # Stop the scientific notation of

return_mat <- impute_missing_returns(return_mat, impute_returns_method = "Drawn_Distribution_Collective", Seed = as.numeric(format( Sys.time(), "%Y%d%H%M")))

return_mat_Nodate <- data.matrix(return_mat[, -1])

# Simple Sample covariance and mean:

Sigma <- RiskPortfolios::covEstimation(return_mat_Nodate)

Mu <- RiskPortfolios::meanEstimation(return_mat_Nodate)

#PCA calculations

pca <- prcomp(return_mat_Nodate,center=TRUE, scale.=TRUE)


# Plot

fviz_screeplot(pca, ncp = 10)
```

```{r}
fviz_pca_var(pca, col.var = "steelblue") + theme_minimal()

fviz_contrib(pca, choice = "var", axes = 1, top = 10)

fviz_contrib(pca, choice = "var", axes = 2, top = 10)

```

* Calculate Rolling Correlation


```{r}

# Calculate rolling constituent correlation

df_Q4 <- T40_Q4

#df_Q4 %>% head(5) %>% pretty_table()

# rolling correlation calculation

pairwise_corrs <- rolling_cor_func(df_Q4, 90) %>% 
    
    ungroup() %>%
    
    filter(date > as.Date("2012/03/28"))

# Determine Mean 

Mean_pair_cor <- pairwise_corrs %>% 
    
    group_by(Tickers) %>% 
    
    summarise(Mean_Cor = mean(rollingcor)) 


# Plot Mean over time
mean_pw_cors <- pairwise_corrs %>%
    
  group_by(date) %>%
    
  summarise(mean_pw_corr = mean(rollingcor, na.rm = TRUE))

mean_cor_plot <- mean_pw_cors %>% 
    
    ggplot() + 
    
    geom_line(aes(date, mean_pw_corr), alpha = 0.8, color ="steelblue") +
    
    fmx_cols() + 
    
    theme_fmx(title = ggpts(25)) + 
    
    labs(y = "Rolling Mean Constituent Correlation", 
         x = "", title = "90-day Mean Rolling Constituent Correlation")

finplot(mean_cor_plot)


```





# Question 5

```{r}
# Load Data

cncy <- read_rds("data/currencies.rds")

cncy_Carry <- read_rds("data/cncy_Carry.rds")

cncy_value <- read_rds("data/cncy_value.rds")

cncyIV <- read_rds("data/cncyIV.rds")

bbdxy <- read_rds("data/bbdxy.rds")

```


## Volatility

```{r}
## To analyse whether the Rand is volatile lets look at Implied volatility
# What cuurencies are in the data?

cncyIV %>% group_by(Name) %>% pull(Name) %>% unique 
```

```{r}
IV_plot <- cncyIV %>% 
    
    filter(Name==c("China_IV", "India_IV", "SouthAfrica_IV",
                   "UK_IV", "EU_IV", "Singapore_IV")) %>%
    
    filter(date > as.Date("1999-12-31")) %>% 
    
    group_by(date) %>%
    
    ggplot() + 
    
    geom_line(aes(x=date, y=Price, color=Name)) +
    
    theme_bw() +  
    
    labs(x = "Dates", y = "Price (relative to USD)",
         
         title = "Implied Volatility ", subtitle = "",
         
         caption = "Note:\nOwn Calculations") +
    
    guides(col=guide_legend("Currency"))

IV_plot
```


This suggests that the market foresees the highest future volatility for the Rand, for this sub-sample.


```{r}


# Calculating Returns and Cleaning

zar_rtn <- cncy %>% 
    
    arrange(date) %>% 
    
    filter(date > as.Date("1999-12-31")) %>% 
    
    filter(Name %in% "SouthAfrica_Cncy") %>% 
    
    mutate(Price = na.locf(Price)) %>% 
    
    mutate(dlogret = log(Price) - log(lag(Price))) %>% 
    
    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>% 
    
    filter(date > dplyr::first(date)) 

xts_zar_rtn <- zar_rtn %>% 
    
    tbl_xts(., cols_to_xts = "dlogret", spread_by = "Name")

MarchTest(xts_zar_rtn)
```


```{r}
xts_zar_rtn[is.na(xts_zar_rtn)] <- 0

PlotRtn = cbind(xts_zar_rtn, xts_zar_rtn^2, abs(xts_zar_rtn))

colnames(PlotRtn) = c("Returns", "Returns_Sqd", "Returns_Abs")

PlotRtn <- PlotRtn %>% 
    
    xts_tbl() %>%
    
    gather(ReturnType, Returns, -date) 

# Plot

ggplot(PlotRtn) + 
    
    geom_line(aes(x = date, y = Returns, colour = ReturnType, alpha = 0.5)) + 
    
    ggtitle("Return Type Persistence: USD/ZAR") + 
    
    facet_wrap(~ReturnType, nrow = 3, ncol = 1, scales = "free") + 
    
    guides(alpha = "none", colour = "none") + 
    
    fmxdat::theme_fmx()


```


```{r}
forecast::Acf(xts_zar_rtn, main = "ACF: Equally Weighted Return")
```

```{r}
forecast::Acf(xts_zar_rtn, main = "ACF: Equally Weighted Return")
```

```{r}
forecast::Acf(xts_zar_rtn^2, main = "ACF: Squared Equally Weighted Return")
```

```{r}
forecast::Acf(abs(xts_zar_rtn), main = "ACF: Absolute Equally Weighted Return")
```

```{r}
Box.test(coredata(xts_zar_rtn^2), type = "Ljung-Box", lag = 12)
```

# Find best model

```{r}

best_model <- Vol_Model_Sel(zar_rtn)

best_model
```

# Fit Model

```{r}

garch_fit_gjrGARCH <- vol_func(zar_rtn, "gjrGARCH")

garch_fit_sGARCH <- vol_func(zar_rtn, "sGARCH")

signbias(garch_fit_sGARCH)
```


```{r, results = 'asis'}

pacman::p_load(xtable)
Table <- xtable(garch_fit_sGARCH@fit$matcoef)

print(Table, type = "latex", comment = FALSE)
```



```{r}
#Conditional variance Plot

persistence(garch_fit_sGARCH)
```


```{r}
# Persistence is alpha + beta, and it is typically very high and close to 1

# To view the conditional variance plot, use:
sigma <- sigma(garch_fit_sGARCH) %>% 
    
    xts_tbl() 

colnames(sigma) <- c("date", "sigma") 

sigma <- sigma %>% 
    
    mutate(date = as.Date(date))

Con_var_plot <- 
  
ggplot() + 
    
  geom_line(data = PlotRtn %>% filter(ReturnType == "Returns_Sqd") %>% 
                
                select(date, Returns) %>% 
              
              unique %>% mutate(Returns = sqrt(Returns)), 
            
            aes(x = date, y = Returns)) + 
  
  geom_line(data = sigma, aes(x = date, y = sigma), 
            color = "red", size = 2, alpha = 0.8) + 
  
  
  labs(title = "Comparison: Returns Sigma vs Sigma from Garch", 
       
       subtitle = "Note the smoothing effect of garch, as noise is controlled for.", x = "", y = "Comparison of estimated volatility",
       
       caption = "Source: Fin metrics class | Calculations: Own") + 
  
    fmxdat::theme_fmx(CustomCaption = TRUE)


fmxdat::finplot(Con_var_plot, y.pct = T, y.pct_acc = 1)

```

```{r}
news_plot <- newsimpact(z = NULL, garch_fit_sGARCH)

plot(news_plot$zx, news_plot$zy, ylab = news_plot$yexpr, xlab = news_plot$xexpr, type = "l", 
    main = "News Impact Curve")
```

```{r}

plot(garch_fit_sGARCH, which = "all")
```


```{r}
# Lets investigate further
# lets compare Smoothed ZAR Vol to mean Global VOL

# Calculate Mean Global VOL

mean_Gvol <- cncyIV %>% 
    
    filter(date > as.Date("1999-12-31")) %>% 
    
    group_by(date) %>% 
    
    summarise(mean_vol = mean(Price)) %>% 
    
    mutate(Global_vol = mean_vol/max(mean_vol))

# Wrangle Sigma 

sigma <- sigma %>% 
    
    mutate(Date = as.Date(date)) %>% 
    
    mutate(ZAR_sigma = sigma/max(sigma))%>%
    
    left_join(., mean_Gvol, by = "date")

# Plot 

Vol_compare_plot <- sigma %>% 
    
    select(-date) %>% 
    
    pivot_longer(c("ZAR_sigma", "Global_vol"), 
                 names_to = "Vol_type", 
                 values_to = "VOL") %>%
    
    ggplot() +
    
    geom_line(aes(Date, VOL, colour = Vol_type)) +
    
    labs(title = "ZAR Volatility and Mean Currency Volatility",
         x = "", 
         y = "Proprotion of Max Vol") +
    
    fmx_cols() +
    
    theme_fmx(title.size = ggpts(25)) 

finplot(Vol_compare_plot)

```


# Question 6

```{r}
# Load Data
pacman::p_load("MTS", "robustbase")
pacman::p_load("tidyverse", "devtools", "rugarch", "rmgarch", 
    "forecast", "tbl2xts", "lubridate", "PerformanceAnalytics", 
    "ggthemes")

msci <- read_rds("data/msci.rds")
bonds <- read_rds("data/bonds_10y.rds")
comms <- read_rds("data/comms.rds")
```


```{r, include=FALSE}
# Calculate Returns for Assets

# 1. First Calculate Returns for MSCI All Country World Index
# For last decade

Equities <- msci %>%
    
    group_by(Name) %>% 
    
    filter(Name %in% "MSCI_ACWI") %>% 
    
    mutate(dlogret = log(Price) - log(lag(Price))) %>%
    
    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>% 
    
    filter(date > dplyr::first(date)) %>% 
    
    select(-Price) %>%
    
    filter(date > as.Date("2009-12-31")) %>% 
    
    rename(MSCI_ACWI = scaledret) %>%
    
    select(date, MSCI_ACWI)

# 2. Calculate US 10 Year Bond Returns

US_bond <- bonds %>%
    
    group_by(Name) %>%
    
    filter(Name %in% "US_10Yr") %>% 
    
    mutate(dlogret = Bond_10Yr/lag(Bond_10Yr) - 1) %>%
    
    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>% 
    
    filter(date > dplyr::first(date)) %>% 
    
    select(-Bond_10Yr) %>%
    
    filter(date > as.Date("2009-12-31"))%>%
    
    rename(US_10Yr = scaledret) %>%
    
    select(date, US_10Yr)

# 3. Calculate Global Real Estate Returns

Real_Estate <- msci %>% 
    
    group_by(Name) %>%
    
    filter(Name %in% "MSCI_RE") %>% 
    
    mutate(dlogret = log(Price) - log(lag(Price))) %>% 
    
    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>% 
    
    filter(date > dplyr::first(date)) %>% 
    
    select(-Price) %>%
    
    filter(date > as.Date("2009-12-31")) %>% 
    
    rename(MSCI_RE = scaledret) %>%
    
    select(date, MSCI_RE)

# 4. Calculate Oil Returns

Oil <- comms %>% 
    
    group_by(Name) %>%
    
    filter(Name %in% "Oil_Brent" ) %>% 
    
    mutate(dlogret = log(Price) - log(lag(Price))) %>% 
    
    mutate(scaledret = (dlogret - mean(dlogret, na.rm = T))) %>% 
    
    filter(date > dplyr::first(date)) %>%
    
    select(-Price) %>%
    
    filter(date > as.Date("2009-12-31")) %>%
    
    rename(Oil_Brent = scaledret) %>%
    
    select(date, Oil_Brent)

# Combine and wrangle for DCC models

asset_classes_ret <- left_join(Equities, US_bond, by = c("date")) %>% 
    
    left_join(., Real_Estate, by = c("date")) %>% 
    
    left_join(., Oil, by = c("date")) %>% 
    
    tbl_xts()

```


```{r}
# Lets test for autocorrelation using the March Test

MarchTest(asset_classes_ret)
```


The MARCH test indicates that all the MV portmanteau tests reject the null of no conditional heteroskedasticity, motivating our use of MVGARCH models. Let's set up the model


```{r}
# GARCH specifications

uspec <- ugarchspec(variance.model = list(model = "gjrGARCH", 
    garchOrder = c(1, 1)), mean.model = list(armaOrder = c(1, 
    0), include.mean = TRUE), distribution.model = "sstd")

multi_univ_garch_spec <- multispec(replicate(ncol(asset_classes_ret), uspec))

# DCC specifications

spec.dcc = dccspec(multi_univ_garch_spec, dccOrder = c(1, 1), 
    distribution = "mvnorm", lag.criterion = c("AIC", "HQ", "SC", 
        "FPE")[1], model = c("DCC", "aDCC")[1])  

# Enable clustering for speed:

cl = makePSOCKcluster(10)

# Fit GARCH

multf = multifit(multi_univ_garch_spec, asset_classes_ret, cluster = cl)

# Fit DCC

fit.dcc = dccfit(spec.dcc, data = asset_classes_ret, solver = "solnp", 
    cluster = cl, fit.control = list(eval.se = FALSE), fit = multf)

# Check Model

RcovList <- rcov(fit.dcc)

covmat = matrix(RcovList, nrow(asset_classes_ret), ncol(asset_classes_ret) * ncol(asset_classes_ret), 
    byrow = TRUE)

mc1 = MCHdiag(asset_classes_ret, covmat)

```

```{r}
# Wrangle output
dcc.time.var.cor <- rcor(fit.dcc)
print(dcc.time.var.cor[, , 1:3])

dcc.time.var.cor <- aperm(dcc.time.var.cor, c(3, 2, 1))
dim(dcc.time.var.cor) <- c(nrow(dcc.time.var.cor), ncol(dcc.time.var.cor)^2)
```

```{r}
# Rename Output

dcc.time.var.cor <- renamingdcc(ReturnSeries = asset_classes_ret, DCC.TV.Cor = dcc.time.var.cor)

# Now we can plot ;)

# Equities

DCC_eq_plot <- ggplot(dcc.time.var.cor %>% 
                          
                          filter(grepl("MSCI_ACWI_", Pairs), 
                                 !grepl("_MSCI_ACWI", Pairs))) + 
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
    
    theme_hc() + labs(subtitle = "Dynamic Conditional Correlations: MSCI_ACWI", x = "", y = "") +
    
    fmx_cols() + 
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))


# US Bonds
DCC_bond_plot <- ggplot(dcc.time.var.cor %>% 
                            
                            filter(grepl("US_10Yr_", Pairs), 
                                   !grepl("_US_10Yr", Pairs))) + 
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) + theme_hc() + 
    
    labs(subtitle="Dynamic Conditional Correlations: US_10Yr", x = "", y = "") +
    
    fmx_cols() + 
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))


# Real Estate

DCC_RE_plot <- ggplot(dcc.time.var.cor %>% 
                          
                          filter(grepl("MSCI_RE_", Pairs), 
                                 !grepl("_MSCI_RE", Pairs))) + 
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) + theme_hc() + 
    
    labs(subtitle = "Dynamic Conditional Correlations: MSCI_RE", x = "", y = "") +
    
    fmx_cols() + 
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))



# Oil

DCC_oil_plot <- ggplot(dcc.time.var.cor %>% 
                           
                           filter(grepl("Oil_Brent_", Pairs), 
                                  !grepl("_Oil_Brent", Pairs))) +
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
    
    theme_hc() + 
    
    labs(subtitle = "Dynamic Conditional Correlations: Oil_Brent", x = "", y = "") +
    
    fmx_cols() + 
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))


```


```{r}
plot_grid(DCC_eq_plot, DCC_bond_plot, DCC_RE_plot , DCC_oil_plot, labels = c('', '', '',''))
```

* Go Garch

```{r}
# Go-GARCH following the Tutorial

# GARCH Specifications
spec.go <- gogarchspec(multi_univ_garch_spec, 
                       distribution.model = 'mvnorm', 
                       ica = 'fastica') 

# Speed:

cl <- makePSOCKcluster(10)

# Fit GARCH

multf <- multifit(multi_univ_garch_spec, asset_classes_ret, cluster = cl)

#GO-GARCH Specifications

fit.gogarch <- gogarchfit(spec.go, 
                      data = asset_classes_ret, 
                      solver = 'hybrid', 
                      cluster = cl, 
                      gfun = 'tanh', 
                      maxiter1 = 40000, 
                      epsilon = 1e-08, 
                      rseed = 100)

# Go-Garch Fit

print(fit.gogarch)

```

```{r}

# Wrangle Output

gog.time.var.cor <- rcor(fit.gogarch)

gog.time.var.cor <- aperm(gog.time.var.cor,c(3,2,1))

dim(gog.time.var.cor) <- c(nrow(gog.time.var.cor), ncol(gog.time.var.cor)^2)

# Rename Output

gog.time.var.cor <- renamingdcc(ReturnSeries = asset_classes_ret, DCC.TV.Cor = gog.time.var.cor)


# Plots

# Equities

GO_eq_plot <- ggplot(gog.time.var.cor %>% 
                   
                   filter(grepl("MSCI_ACWI_", Pairs), 
                          !grepl("_MSCI_ACWI", Pairs))) + 
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) +
    
    theme_hc() + 
    
    labs(subtitle = "Go-Garch: MSCI_ACWI", x = "", y = "") +
    
    fmx_cols() + 
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))

# Bonds

GO_bond_plot <- ggplot(gog.time.var.cor %>% 
                   
                   filter(grepl("US_10Yr_", Pairs), !grepl("_US_10Yr", Pairs))) +
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
    
    theme_hc() + 
    
    labs(subtitle="Go-Garch: US_10Yr", x = "", y = "") +
    
    fmx_cols() + 
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))

# Real Estate

GO_RE_plot <- ggplot(gog.time.var.cor %>%
                   
                   filter(grepl("MSCI_RE_", Pairs), !grepl("_MSCI_RE", Pairs))) +
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
    
    theme_hc() +
    
    labs(subtitle = "Go-Garch: MSCI_RE", x = "", y = "") +
    
    fmx_cols() +
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))


# Commodities

GO_oil_plot <- ggplot(gog.time.var.cor %>%
                   
                   filter(grepl("Oil_Brent_", Pairs), !grepl("_Oil_Brent", Pairs))) + 
    
    geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
    
    theme_hc() + 
    
    labs(subtitle = "Go-GARCH: Oil_Brent", x = "", y = "") +
    
    fmx_cols() + 
    
    theme_fmx(subtitle.size = ggpts(25), legend.size = ggpts(15))


```


```{r}
plot_grid(GO_eq_plot, GO_bond_plot, GO_RE_plot , GO_oil_plot, labels = c('', '', '',''))

```

```{r}
library(factoextra)
library(FactoMineR)
pacman::p_load("psych")

eq_pca <- msci %>% 
    
    spread(Name, Price) %>% 
    
    select(date, MSCI_ACWI)

bond_pca <- bonds %>% 
    
    spread(Name, Bond_10Yr) %>% 
    
    select(date, US_10Yr)

Re_pca <- msci %>% 
    
    spread(Name, Price) %>% 
    
    select(date, MSCI_RE)
    
oil_pca <- comms %>%  
    
    spread(Name, Price) %>% 
    
    select(date, Oil_Brent)

# Combine

asset_class_pca <- left_join(eq_pca, bond_pca, by = c("date")) %>% 
    
    left_join(., Re_pca, by = c("date")) %>% 
    
    left_join(., oil_pca, by = c("date")) %>% 
    
    gather(Tickers, Price, -date) %>%
    
    group_by(Tickers) %>%
    
    filter(date > as.Date("2009-12-31")) %>% 
    
    arrange(date) %>%  
    
    group_by(Tickers) %>%  
    
    mutate(dlogret = log(Price) - log(lag(Price))) %>% 
    
    mutate(scaledret = (dlogret -  mean(dlogret, na.rm = T))) %>% 
    
    filter(date > dplyr::first(date)) %>% 
    
    ungroup()


asset_classes_pca <- asset_class_pca %>%  
    
    select(date, Tickers, dlogret) %>% 
    
    spread(Tickers, dlogret) %>% 
    
    select(-date)

AC_PCA_plot <- prcomp(asset_classes_pca, center = TRUE, scale. = TRUE)

AC_PCA_plot$rotation

pairs.panels(asset_classes_pca)

```

```{r}
gviolion <- asset_classes_pca %>% 
    
    gather(Type, val) %>% 
    
    ggplot() + 
    
    geom_violin(aes(Type, val, fill = Type), alpha = 0.7) +
    
    fmxdat::theme_fmx() + 
    
    fmxdat::fmx_fills()

fmxdat::finplot(gviolion, y.pct = T, y.pct_acc = 1, x.vert = T)

```


# Question 7
## # Load in Data

```{r}

MAA <- read_rds("data/MAA.rds")

msci <- read_rds("data/msci.rds") %>%
    
    filter(Name %in% c("MSCI_ACWI", "MSCI_USA", "MSCI_RE", "MSCI_Jap"))

```


```{r}

library(rmsfuns)
pacman::p_load("tidyr", "tbl2xts","devtools","lubridate", "readr", "PerformanceAnalytics", "ggplot2", "dplyr")

# quarter

quarter_dates <- dateconverter(as.Date("2018-01-01"), as.Date("2021-10-29"), 
    "weekdayEOQ") 

# Cal returns for MAA

MAA <- MAA %>% 
    
    arrange(date) %>% 
    
    rename(Tickers = Name) %>% 
    
    filter(date %in% quarter_dates) %>% 
    
    group_by(Tickers) %>% 
    
    mutate(Return = Price / lag(Price)-1) %>% 
    
    ungroup() %>% 
    
    select(date, Tickers, Return) %>% 
    
    filter(!is.na(Return)) %>% 
    
    mutate(YearMonth = format(date, "%Y%B"))

# Cal returns for MAA

msci_q7 <- msci %>% 
    
    arrange(date) %>% 
    
    rename(Tickers = Name) %>%
    
    filter(date %in% quarter_dates) %>%
    
    group_by(Tickers) %>% 
    
    mutate(Return = Price / lag(Price)-1) %>% 
    
    ungroup() %>% 
    
    select(date, Tickers, Return) %>% 
    
    filter(!is.na(Return)) %>% 
    
    mutate(YearMonth = format(date, "%Y%B"))

# Combine

combine_assets_tut <- rbind(MAA, msci_q7) %>% 
    
    arrange(date)

# Consider only indexes with data from before 20080101, and use this as a common start date too...:
# Can you argue why?

#combine_assets_3yrtut <- combine_assets_tut %>% 
    
#    group_by(Tickers) %>% 
    
#    filter(date == first(date)) %>% 
    
#    ungroup() %>% 
    
#    filter(date < ymd(20180101)) %>% 
    
#    pull(Tickers) %>% 
    
#    unique

#combine_assets_tut <- combine_assets_tut %>% 
  
#  filter(Tickers %in% combine_assets_3yrtut) %>% 
  
#  filter(date > ymd(20180101))

```


```{r}

# Impute missing values for return series
return_mat_q7 <- combine_assets_tut %>%
    
    select(date, Tickers, Return) %>% 
    
    spread(Tickers, Return)

options(scipen = 999)

return_mat_q7 <- impute_missing_returns(return_mat_q7,
                           impute_returns_method = "Drawn_Distribution_Collective", Seed =
                               as.numeric(format( Sys.time(), "%Y%d%H%M")))

# Create returns matrix

return_mat__q7_Nodate <- data.matrix(return_mat_q7[, -1])



```


```{r}
# Create constraints

NStox <- ncol(return_mat__q7_Nodate)
LB = 0.01
UB = 0.4
Eq = 0.6 # Equity exposure
Bonds = 0.25 # Credit and Bonds exposure
meq = 1

# A Mat 
Eq_mat <- rbind(matrix(0, nrow = 9, ncol = 4),
                -diag(4))

C_B_mat <- rbind(matrix(0, 3, 6), 
                 -diag(6),
                 matrix(0, 4, 6))

bvec <- c(1, rep(LB, NStox), -rep(UB, NStox), -rep(Eq, 4), -rep(Bonds, 6))

Amat <- cbind(1, diag(NStox), -diag(NStox), Eq_mat, C_B_mat)
```

```{r}

# Calculate optimal rolling weights for each type of portfolio optimization

EOM_datevec <- combine_assets_tut %>% 
    
    #filter(Tickers %in% comb_assets_3_years) %>% 
    
    #filter(date >= Start_Date[[1]]) %>% 
    
    select(date) %>% 
    
    unique %>% 
    
    mutate(YM = format(date, "%Y%B")) %>% 
    
    group_by(YM) %>% 
    
    filter(date == dplyr::last(date)) %>% 
    
    ungroup() %>% 
    
    pull(date) %>% 
    
    unique

Opt_roll_wgt <- EOM_datevec %>% 
    
    map_df(~Roll_optimizer(return_mat_q7, EOM_datevec = ., Amat = Amat, bvec = bvec, LookBack = 12))

head(Opt_roll_wgt, 10)

```
